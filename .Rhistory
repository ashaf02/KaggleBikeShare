?hist
# Your data
data <- c(
2.333333333, 2.333333333, 3.333333333, 3.333333333, 3.333333333, 3.666666667,
3.0, 4.0, 4.0, 4.0, 4.333333333, 4.0, 4.0, 4.0, 4.333333333, 5.0, 5.0, 5.333333333,
5.0, 5.333333333, 5.333333333, 3.333333333, 4.333333333, 4.333333333, 4.333333333,
4.666666667, 4.333333333, 4.333333333, 4.333333333, 4.666666667, 5.333333333,
5.333333333, 5.666666667, 5.333333333, 5.666666667, 5.666666667, 5.0, 5.0, 5.0,
5.333333333, 6.0, 6.0, 6.333333333, 6.0, 6.333333333, 6.333333333, 6.0, 6.0,
6.333333333, 6.0, 6.333333333, 6.333333333, 7.0, 7.333333333, 7.333333333, 7.333333333
)
# Create a histogram for the sample means
hist(data, breaks = 10, col = "blue", xlab = "Sample Mean (y-bar)", main = "Histogram of Sample Mean (y-bar)")
# Create a histogram for the sample means
hist(data, breaks = 10, col = "lightblue", xlab = "Sample Mean (y-bar)", main = "Histogram of Sample Mean (y-bar)")
# Create a histogram for the sample means
hist(data, breaks = 10, col = "lightblue", xlab = "Sample Mean (y-bar)", main = "Histogram of Sample Mean")
# Your data
data2 <- c(
1, 1.333333333, 2, 2, 3, 3, 3, 3.333333333, 1.333333333, 1.666666667, 2.333333333, 2.333333333,
3.333333333, 3.333333333, 3.333333333, 3.666666667, 2, 2.333333333, 3, 3, 4, 4, 4, 4.333333333,
2, 2.333333333, 3, 3, 4, 4, 4, 4.333333333, 3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333,
3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333, 3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333,
3.333333333, 3.666666667, 4.333333333, 4.333333333, 5.333333333, 5.333333333, 5.333333333, 5.666666667,
1.333333333, 1.666666667, 2.333333333, 2.333333333, 3.333333333, 3.333333333, 3.333333333, 3.666666667,
1.666666667, 2, 2.666666667, 2.666666667, 3.666666667, 3.666666667, 3.666666667, 4, 2.333333333,
2.666666667, 3.333333333, 3.333333333, 4.333333333, 4.333333333, 4.333333333, 4.666666667, 2.333333333,
2.666666667, 3.333333333, 3.333333333, 4.333333333, 4.333333333, 4.333333333, 4.666666667, 3.333333333,
3.666666667, 4.333333333, 4.333333333, 5.333333333, 5.333333333, 5.333333333, 5.666666667, 3.333333333,
3.666666667, 4.333333333, 4.333333333, 5.333333333, 5.333333333, 5.333333333, 5.666666667, 3.333333333,
3.666666667, 4.333333333, 4.333333333, 5.333333333, 5.333333333, 5.333333333, 5.666666667, 3.666666667,
4, 4.666666667, 4.666666667, 5.666666667, 5.666666667, 5.666666667, 6,
2, 2.333333333, 3, 3, 4, 4, 4, 4.333333333,
2.333333333, 2.666666667, 3.333333333, 3.333333333, 4.333333333, 4.333333333, 4.333333333, 4.666666667,
3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333,
3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333,
4, 4.333333333, 5, 5, 6, 6, 6, 6.333333333, 4, 4.333333333, 5, 5, 6, 6, 6, 6.333333333,
4, 4.333333333, 5, 5, 6, 6, 6, 6.333333333, 4.333333333, 4.666666667, 5.333333333, 5.333333333, 6.333333333,
6.333333333, 6.333333333, 6.666666667, 2, 2.333333333, 3, 3, 4, 4, 4, 4.333333333,
2.333333333, 2.666666667, 3.333333333, 3.333333333, 4.333333333, 4
)
# Create a histogram for the sample means
hist(data2, breaks = 10, col = "lightblue", xlab = "Sample Mean (y-bar)", main = "Histogram of Sample Mean")
# Create a histogram for the sample means
hist(data, breaks = 10, col = "lightblue", xlab = "Sample Mean (y-bar)", main = "Histogram of Sample Mean")
# Your data
data2 <- c(
1, 1.333333333, 2, 2, 3, 3, 3, 3.333333333, 1.333333333, 1.666666667, 2.333333333, 2.333333333,
3.333333333, 3.333333333, 3.333333333, 3.666666667, 2, 2.333333333, 3, 3, 4, 4, 4, 4.333333333,
2, 2.333333333, 3, 3, 4, 4, 4, 4.333333333, 3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333,
3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333, 3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333,
3.333333333, 3.666666667, 4.333333333, 4.333333333, 5.333333333, 5.333333333, 5.333333333, 5.666666667,
1.333333333, 1.666666667, 2.333333333, 2.333333333, 3.333333333, 3.333333333, 3.333333333, 3.666666667,
1.666666667, 2, 2.666666667, 2.666666667, 3.666666667, 3.666666667, 3.666666667, 4, 2.333333333,
2.666666667, 3.333333333, 3.333333333, 4.333333333, 4.333333333, 4.333333333, 4.666666667, 2.333333333,
2.666666667, 3.333333333, 3.333333333, 4.333333333, 4.333333333, 4.333333333, 4.666666667, 3.333333333,
3.666666667, 4.333333333, 4.333333333, 5.333333333, 5.333333333, 5.333333333, 5.666666667, 3.333333333,
3.666666667, 4.333333333, 4.333333333, 5.333333333, 5.333333333, 5.333333333, 5.666666667, 3.333333333,
3.666666667, 4.333333333, 4.333333333, 5.333333333, 5.333333333, 5.333333333, 5.666666667, 3.666666667,
4, 4.666666667, 4.666666667, 5.666666667, 5.666666667, 5.666666667, 6,
2, 2.333333333, 3, 3, 4, 4, 4, 4.333333333,
2.333333333, 2.666666667, 3.333333333, 3.333333333, 4.333333333, 4.333333333, 4.333333333, 4.666666667,
3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333,
3, 3.333333333, 4, 4, 5, 5, 5, 5.333333333,
4, 4.333333333, 5, 5, 6, 6, 6, 6.333333333, 4, 4.333333333, 5, 5, 6, 6, 6, 6.333333333,
4, 4.333333333, 5, 5, 6, 6, 6, 6.333333333, 4.333333333, 4.666666667, 5.333333333, 5.333333333, 6.333333333,
6.333333333, 6.333333333, 6.666666667, 2, 2.333333333, 3, 3, 4, 4, 4, 4.333333333,
2.333333333, 2.666666667, 3.333333333, 3.333333333, 4.333333333, 4
)
# Create a histogram for the sample means
hist(data2, breaks = 10, col = "lightblue", xlab = "Sample Mean (y-bar)", main = "Histogram of Sample Mean")
setwd("C:/Users/amand/OneDrive/Desktop/Fall 2023/STAT 234")
library(tidyverse)
library(tidymodels)
library(vroom)
Lockhart <- vroom("Lockhart.csv")
Lockhart <- vroom("LockHart.csv")
install.packages("openxlsx")
library(openxlsx)
lockhart_data <- read.xlsx("LockHart.xlsx")
list.files()  # Lists files in the current working directory
list.files()  # Lists files in the current working directory
library(readxl)
lockhart_data <- read_excel("LockHart.xlsx")
lockhart_data <- read_excel("LockHart.xlsx")
head(lockhart_data)
avg?
?avg
?average
a <- mean(lockhart_data$Price)
a
b <- mean(lockhart_data$TVSets)
b
## c
filtered_data <- lockhart_data[lockhart_data$Price >= 10, ]
proportion_above_10 <- nrow(filtered_data) / nrow(lockhart_data)
c <- proportion_above_10
c
# Population and sample sizes
N <- 31989
n <- 200
# Calculate the fpc
fpc <- 1 - n / N
# Create a survey design object with the fpc
survey_design <- svydesign(ids = ~1, fpc = fpc)
install.packages("survey")
library(readxl)
library(survey)
library(survey)
# Population and sample sizes
N <- 31989
n <- 200
# Calculate the fpc
fpc <- 1 - n / N
# Create a survey design object with the fpc
survey_design <- svydesign(ids = ~1, fpc = fpc)
## Libraries I am going to need
library(tidyverse)
library(tidymodels)
library(vroom)
## Read in the data
bikeTrain <- vroom("train.csv")
setwd("C:/Users/amand/OneDrive/Desktop/Fall 2023/STAT348/KaggleBikeShare")
## Read in the data
bikeTrain <- vroom("train.csv")
bikeTest <- vroom("test.csv")
## Remove casual and registered because we can't use them to predict
bikeTrain <- bikeTrain %>%
select(-casual, - registered)
## Cleaning & Feature Engineering
bike_recipe <- recipe(count~., data=bikeTrain) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("Sunny", "Mist", "Rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("Spring", "Summer", "Fall", "Winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("No", "Yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("No", "Yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime)
prepped_recipe <- prep(bike_recipe)
bake(prepped_recipe, new_data = bikeTrain) #Make sure recipe work on train
bake(prepped_recipe, new_data = bikeTest) #Make sure recipe works on test
## Define the model
lin_model <- linear_reg() %>%
set_engine("lm")
## Set up the whole workflow
bike_workflow <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(lin_model) %>%
fit(data=bikeTrain)
## Look at the fitted LM model this way
extract_fit_engine(bike_workflow) %>%
summary()
## Get Predictions for test set AND format for Kaggle
test_preds <- predict(bike_workflow, new_data = bikeTest) %>%
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
## Trying Poisson Model
pois_mod <- poisson_reg() %>% #Type of model
set_engine("glm") # GLM = generalized linear model
bike_pois_workflow <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(pois_mod) %>%
fit(data = bikeTrain) # Fit the workflow
bike_predictions_pois <- predict(bike_pois_workflow,
new_data=bikeTest) # Use fit to predict
bike_pois_workflow <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(pois_mod) %>%
fit(data = bikeTrain) # Fit the workflow
bike_predictions_pois <- predict(bike_pois_workflow,
new_data=bikeTest) # Use fit to predict
library(poissonreg)
bike_pois_workflow <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(pois_mod) %>%
fit(data = bikeTrain) # Fit the workflow
bike_predictions_pois <- predict(bike_pois_workflow,
new_data=bikeTest) # Use fit to predict
## Get Predictions for test set AND format for Kaggle
test_preds_pois <- predict(bike_pois_workflow, new_data = bikeTest) %>%
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
## Get Predictions for test set AND format for Kaggle
test_preds_pois <- predict(bike_pois_workflow, new_data = bikeTest) %>%
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) %>% #needed for right format to Kaggle
step_dummy(all_nominal_predictors()) %>% #make dummy variables7
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
## Get Predictions for test set AND format for Kaggle
test_preds_pois <- predict(bike_pois_workflow, new_data = bikeTest) %>%
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) %>% #needed for right format to Kaggle
step_dummy(all_nominal_predictors()) %>% #make dummy variables7
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
## Get Predictions for test set AND format for Kaggle
test_preds_pois <- predict(bike_pois_workflow, new_data = bikeTest) %>%
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
install.packages("glmnet")
library(glmnet)
## Transform to log(count) - I can only do this on train set because
## test set does not have count.  Hence, I am doing this outside of recipe
## because I only apply this to the train set
logTrainSet <- bikeTrain %>%
mutate(count=log(count))
## Define the model
lin_model <- linear_reg() %>%
set_engine("lm")
## Set up the whole workflow
log_lin_workflow <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(lin_model) %>%
fit(data=logTrainSet) #Make sure to use the log(count) dataset
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(log_lin_workflow, new_data = bikeTest) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(log_lin_workflow, new_data = bikeTest) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) %>% #needed for right format to Kaggle
step_dummy(all_nominal_predictors()) %>% #make dummy variables7
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
## Libraries I am going to need
library(tidyverse)
library(tidymodels)
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(log_lin_workflow, new_data = bikeTest) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) %>% #needed for right format to Kaggle
step_dummy(all_nominal_predictors()) %>% #make dummy variables7
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
## Set up the whole workflow
log_lin_workflow <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(lin_model) %>%
fit(data=logTrainSet) #Make sure to use the log(count) dataset
## Get Predictions for test set AND format for Kaggle
log_lin_preds <- predict(log_lin_workflow, new_data = bikeTest) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
## Write predictions to CSV
vroom_write(x=log_lin_preds, file="./LogLinearPreds.csv", delim=",")
## Cleaning & Feature Engineering
bike_recipe <- recipe(count~., data=bikeTrain) %>%
step_mutate(weather=ifelse(weather==4, 3, weather)) %>% #Relabel weather 4 to 3
step_mutate(weather=factor(weather, levels=1:3, labels=c("Sunny", "Mist", "Rain"))) %>%
step_mutate(season=factor(season, levels=1:4, labels=c("Spring", "Summer", "Fall", "Winter"))) %>%
step_mutate(holiday=factor(holiday, levels=c(0,1), labels=c("No", "Yes"))) %>%
step_mutate(workingday=factor(workingday,levels=c(0,1), labels=c("No", "Yes"))) %>%
step_time(datetime, features="hour") %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>% #make dummy variables7
step_normalize(all_numeric_predictors()) # Make mean 0, sd=1
prepped_recipe <- prep(bike_recipe)
bake(prepped_recipe, new_data = bikeTrain) #Make sure recipe work on train
bake(prepped_recipe, new_data = bikeTest) #Make sure recipe works on test
## Penalized log-lin regression model
preg_model <- linear_reg(penalty=1, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- log_lin_workflow() %>%
add_recipe(bike_recipe) %>%
add_model(preg_model) %>%
fit(data=logTrainSet)
## Transform to log(count) - I can only do this on train set because
## test set does not have count.  Hence, I am doing this outside of recipe
## because I only apply this to the train set
logTrainSet <- bikeTrain %>%
mutate(count=log(count))
## Define the model for log-lin
lin_model <- linear_reg() %>%
set_engine("lm")
## Set up the whole workflow for log-lin
log_lin_workflow <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(lin_model) %>%
fit(data=logTrainSet) #Make sure to use the log(count) dataset
## Get Predictions for test set AND format for Kaggle for log-lin
log_lin_preds <- predict(log_lin_workflow, new_data = bikeTest) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
## Penalized log-lin regression model
preg_model <- linear_reg(penalty=1, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- log_lin_workflow() %>%
add_recipe(bike_recipe) %>%
add_model(preg_model) %>%
fit(data=logTrainSet)
preg_wf <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(preg_model) %>%
fit(data=logTrainSet)
penalized_predictions <- predict(preg_wf, new_data=testData)
penalized_predictions <- predict(preg_wf, new_data=bikeTest)
## Write penalized log predictions to CSV
vroom_write(x=penalized_predictionss, file="./PenLogLinearPreds.csv", delim=",")
## Write penalized log predictions to CSV
vroom_write(x=penalized_predictions, file="./PenLogLinearPreds.csv", delim=",")
penalized_predictions <- predict(preg_wf, new_data=bikeTest)%>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., bikeTest) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
## Write penalized log predictions to CSV
vroom_write(x=penalized_predictions, file="./PenLogLinearPreds.csv", delim=",")
